# Real-World-based-Projects

## 1) Fiverr : End-to-End Project includes Deployment 

**Problem statement -**
Recently attackers are using freelance job sites such as Fiverr to distribute malware disguised as job offers. These job offers contain attachments that pretend to be the job brief but are actually installers for keyloggers such as Agent Tesla or Remote Access Trojan (RATs). Due to this many users lost their earnings, bidding fees and fake client projects, also some users lost their accounts too. Many of my LinkedIn connections faced it and some of them lost their professional growth, side income and stability.

Just after a month of this attack Fiverr come-up with a Kaggle competition on this to understand how data science people will solve this problem by using their differ methods and techniques.

*Objective : - Find a good fit algorithm which will have Potential to Predict Spammers.*

* Note : Also, I will try to deploy my ml model to show that which User ID is spammer or not

***Explore the solution here :- [Fiverr : End-to-End Project includes Deployment notebook](https://www.kaggle.com/code/deepakkaura/fiverr-end-to-end-project-includes-deployment)***

---

## 2) Audit Risk : ML will help !!!  

**Problem Statement and about dataset :-**
The goal of the dataset is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors.

The information about the sectors and the counts of firms are listed respectively as

Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).

This research work is a case study of an external government audit company which is also the external auditor of government firms of India. During audit-planning, auditors examine the business of different government offices but the target to visit the offices with very-high likelihood and significance of misstatements. This is calculated by assessing the risk relevant to the financial reporting goals (Houston, Peters, and Pratt 1999). The three main objective of the study are as follow:

* To understand the audit risk analysis work-flow of the company by in-depth interview with the audit employees, and to propose a decision-making framework for risk assessment of firms during audit planning.

* To examine the present and historical risk factors for determining the Risk Audit Score for 777 target firms, to implement the Particle Swarm Optimization (PSO) algorithm to rank examined risk factors, and evaluating the Risk Audit Class (Fraud and No-Fraud) of nominated firms.

* To examine the present and historical risk factors for determining the Risk Audit Score for 777 target firms, to implement the Particle Swarm Optimization (PSO) algorithm to rank examined risk factors, and evaluating the Risk Audit Class (Fraud and No-Fraud) of nominated firms.

***Explore the solution here :- [Audit notebook](https://www.kaggle.com/code/deepakkaura/audit-risk-ml-will-help)***

---

## 3) IEEE-CIS : A story of Fraud Detection  

**Business Problem :-**
Ever had that awkward moment at the grocery store or any other place when your card gets declined for no apparent reason, causing a ripple of embarrassment? Imagine that, but we're on a mission to fix it!

***Here's the scoop: The brainy folks at IEEE Computational Intelligence Society (IEEE-CIS) and the savvy team at Vesta Corporation want to upgrade the way we catch those sneaky fraudsters. It's like turning the superhero mode on for your credit card.***

I'm using real-world data from Vesta – you know, the folks handling over $18 billion in transactions every year. Picture it as a playground for data science enthusiasts.

So, what's the goal? looking for model that not only accurately identify genuine transactions but also excel in distinguishing fraudulent ones, as represented by the shape of the ROC curve. The higher the area under the curve, the better your model's discrimination ability.

*"It's like upgrading the bouncer at the VIP entrance to your favorite party – only letting in the real VIPs."*

* **Note :- What is fraud detection?**
Fraud detection protects person information, assets, accounts and transactions through the real-time, near-real-time analysis of activities by users and other defined entities. It uses background server-based processes that examine users’ and other defined entities’ access and behavior patterns, and typically compares this information to a profile of what’s expected.

***Explore the solution here :- [Fraud Detection notebook](https://www.kaggle.com/code/deepakkaura/ieee-cis-a-story-of-fraud-detection)***

---

## 4) Finance : The Tale of Loan Approval

**Problem Statement:**

The loan approval dataset serves as a compilation of financial records and related data utilized to assess the qualification of individuals or organizations seeking loans from a lending institution. Key factors within the dataset encompass elements like CIBIL score, income, employment status, loan term, loan amount, assets value, and loan status. The challenge lies in leveraging this dataset for machine learning and data analysis purposes, aiming to create models and algorithms that accurately predict the probability of loan approval based on the provided features.

* **The Goal :-**
Favorite Algorithms vs New Algorithm : When it comes to tackling classification problems, the question arises – are the tried-and-true favorite algorithms still the reigning champions, or should we search for new for potentially more effective solutions? Also exploring the confusion matrix, especially the Type-1 Error, Type-2 Error and True Negative results.

***Explore the solution here :- [Loan Approval with deployment notebook](https://www.kaggle.com/code/deepakkaura/finance-a-tale-of-loan-approval)***

----

## 5) Clustering : a case of churn + telecom sector

**Problem Statement:**

Customer churn is the percentage of customers that stopped using your company's product or service during a certain time frame. There are many approaches to reduce customer churn but for this project we would attempt to predict which customers are the highest risk of churn by using k-means cluster analysis. Outline:

* Look at the different variables to see how it affects churn
* Run a K-means cluster analysis
* Profile the different Clusters

**The Goal :-**
The company will try to create a marketing mix strategy to minimize the Churn rates in the clusters that are the most susespiable to Churn.

***Explore the solution here :- [Clustering case notebook](https://www.kaggle.com/code/deepakkaura/clustering-a-case-of-churn-telecom-sector)***

----

## 6) CLV 2.0 : A Business Solution

**Problem Statement:**

An UK based retail company was curious to know about their customers, so that they can change their business strategies form which they can acquire more customers or to help their customers for retention, also few additional things wants to know that what's the customer worth in terms of Customer Lifetime Value wise, also some insights to know about UK based customers and Non-UK based customers. So that we can decide our approach for prediction wise.

**Customer Lifetime Value is a monetary value that represents the amount of revenue or profit a customer will give the company over the period of the relationship. CLTV demonstrates the implications of acquiring long-term customers compare to short-term customers.**

**Essence of Customer Lifetime Value : -**

(A) It is a number that represents the total amount spent by a single customer on your products or services over their lifespan.

(B) Calculating your CLV will help you understand how your customers have historically interacted with your business and predict how they may interact with you in the future.

(C) Pinpoint trends, such as the length of your typical customer’s lifespan, their purchasing behavior, and most importantly, how much revenue you tend to make from a single customer.

(D) In a more tangible sense, this metric can also help you to better allocate your marketing resources and prevent churning.

(E) It draws meaningful customer segments these segment can help you to identify the needs of the different-different segment, that will helps you to design an effective business plan and also provide a chance to scale your business.

(F) It can figure out the most profitable customers, but how you are going to make a profit from them, it depends on your strategy.

**The Goal :-**
Crafting a robust business solution requires merging critical analyses like RFM (Recency, Frequency, Monetary), Customer Segmentation, and Cohort Analysis. In this I'll highlight CLV 2.0, an enhanced version with a primary focus on predicting Customer Lifetime Value. And dive into the deployment phase for a preview of how we're putting this solution into action.

* *Note - Keep an eye out for CLV 3.0, introducing advanced ML techniques. Exciting enhancements are just around the corner!*

  ***Explore the solution here :- [CLV 2.0 notebook](https://www.kaggle.com/code/deepakkaura/clv-2-0-a-business-solution)***

  -----

## 7) JD Generator : AI (...the NLP advance level)

**Problem Statement:**

In the contemporary job market, Organizations struggle with time-consuming, biased, and inconsistent manual processes when creating job descriptions. Meanwhile an Indian AI startup company (...part of Make in India mission) whose mission to revolutionize the job description creation process. So they were seeking for an Data Science Enthusiast who can help them by building AI app for it.

* ***Note - This problem statement I received during that company's hiring process and also got hired.***

**Job Description :-** It's an detailed document that outlines the responsibilities, duties, qualifications, and other essential aspects of a specific job or role within an organization. It serves as a comprehensive guide for both employers and job seekers, providing clarity on what is expected in terms of tasks, skills, and qualifications.

**Challenges in the Current Landscape:**
* Time-Consuming Manual Processes
* Biases and Inconsistencies
* Customization and Personalization Limitations
* Adapting to a Dynamic Job Market

**Objective:**
* Automate and Accelerate Job Description Creation
* Eliminate Bias and Ensure Consistency
* Enable Customization and Personalization
* Stay Ahead in the Evolving Job Market

***Explore the solution here :- [JD Generator notebook](https://www.kaggle.com/code/deepakkaura/jd-generator-ai-the-nlp-advance-level)***

------

#### Note - Seeking for more projects click here :- [More projects](https://www.kaggle.com/deepakkaura/code)
